{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34d714c-9684-4601-96e1-f4c944bb1747",
   "metadata": {},
   "source": [
    "# LiCE: Likely Counterfactual Explanations\n",
    "[LiCE](https://openreview.net/pdf?id=rGyi8NNqB0) is a method of finding high-quality Counterfactual Explanations. LiCE utilizes a Sum-Product Network, a probabilistic model, to estimate the plausibility (i.e., likelihood) of the counterfactual sample. Through the use of Mixed-Integer Optimization, we are able to find globally optimal (i.e., closest/most likely) counterfactuals, while satisfying various constraints on the data. These can be related to actionability (a feature cannot change or can only increase/decrease), causality (change of one attribute requires change in another) or data type (categorical, ordinal, discrete and real data).\n",
    "\n",
    "In this notebook, we showcase the use of the algorithm with all its parameters.\n",
    "\n",
    "We evaluate on [Give me some credit (GMSC)](https://www.kaggle.com/c/GiveMeSomeCredit/data) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c97ede-1849-4b1c-bee5-bc081d2139e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go one directory up to the root (from examples/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from humancompatible.explain.lice.data import DataHandler, Monotonicity\n",
    "from humancompatible.explain.lice.spn import SPN\n",
    "from humancompatible.explain.lice import LiCE\n",
    "\n",
    "# just a small wrapper of a PyTorch model, we export it to onnx later\n",
    "from nn_model import NNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad528d04-8c59-4a4e-b7ed-1198a7c13555",
   "metadata": {},
   "source": [
    "## Prepare data and models\n",
    "To find counterfactuals, we first need to describe the data constraints. Then we train a Neural Network which we will be explaining and a Sum-Product Network which we will use to estimate plausibility.\n",
    "\n",
    "### Setup data context (mutability, feature types...)\n",
    "We load the data and set up the `DataHandler` with all data constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea63b5d-3949-4ae3-a02e-3a0a18db1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(project_root+\"/data/GMSC.csv\", index_col=0).dropna()\n",
    "X = data[data.columns[1:]]\n",
    "y = data[[\"SeriousDlqin2yrs\"]]\n",
    "\n",
    "# set bounds on feature values\n",
    "# either fixed by domain knowledge\n",
    "bounds = {\"RevolvingUtilizationOfUnsecuredLines\": (0, 1), \"DebtRatio\": (0, 2)}\n",
    "# or take them from the data\n",
    "for col in X.columns:\n",
    "    if col not in bounds:\n",
    "        bounds[col] = (X[col].min(), X[col].max())\n",
    "\n",
    "config = {\n",
    "    \"categ_map\": {}, # categorical features, map from feature names to a list of categ values, e.g. {\"sex\": [\"male\", \"female\"] | if one provides an empty list with a feature name, then all unique values are taken as categories - note that training split does not have to include all values...\n",
    "    \"ordered\": [], # list of featurenames that contain ordered categorical values, e.g. education levels\n",
    "    \"discrete\": [\n",
    "        \"NumberOfTime30-59DaysPastDueNotWorse\",\n",
    "        \"age\",\n",
    "        \"NumberOfOpenCreditLinesAndLoans\",\n",
    "        \"NumberOfTimes90DaysLate\",\n",
    "        \"NumberRealEstateLoansOrLines\",\n",
    "        \"NumberOfTime60-89DaysPastDueNotWorse\",\n",
    "        \"NumberOfDependents\",\n",
    "    ], # contiguous discrete fearures\n",
    "    \"bounds_map\": bounds, # bounds on all contiguous values\n",
    "    \"immutable\": [\"NumberOfDependents\"], # features that cannot change\n",
    "    \"monotonicity\": {\"age\": Monotonicity.INCREASING}, # features that can only increase (or decrease)\n",
    "    \"causal_inc\": [], # causal increase, pairs of features where if one increases, the other one must increase as well, e.g. [(\"education\", \"age\")]\n",
    "    \"greater_than\": [], # inter-feature dependence, one feature must always be > anohter feature, a list of pairs, e.g. [(\"# total missed payments\",  \"# missed payments last year\")]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "dhandler = DataHandler(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    **config,\n",
    "    # optionally, one can provide the list of feature names (and target name) but here we pass pandas dataframe (and a series) with named columns, which will be taken as feature names\n",
    ")\n",
    "\n",
    "# finally, encode the input data\n",
    "X_train_enc = dhandler.encode(X_train, normalize=True, one_hot=True)\n",
    "y_train_enc = dhandler.encode_y(y_train, one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd290112-1fb4-4cfa-b041-fb806b7ccd58",
   "metadata": {},
   "source": [
    "### Train a Neural Network\n",
    "\n",
    "LiCE works with `onnx` files, here we use PyTorch to train and export an example network. Any ReLU network exported to `onnx` will work. Last layer should not contain the sigmoid activation when passed to LiCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af06e906-906e-4882-8f15-d85eac749590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 50/50 [02:32<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "nn = NNModel(dhandler.encoding_width(True), [20, 10], 1)\n",
    "nn.train(X_train_enc, y_train_enc)\n",
    "# output it to ONNX file\n",
    "nn.save_onnx(\"tmp_nn.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd6685-9af5-4af5-acb5-9ab37f01e067",
   "metadata": {},
   "source": [
    "### Train an SPN\n",
    "The Sum-Product Network will allow us to evaluate the likelihood of the Counterfactual. This allows us to find _plausible_ counterfactals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8fd8090-daf0-43e6-93f6-e2c06e7190a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this can take long...\n",
    "# setting \"min_instances_slice\":1000 argument leads to faster training by allowing leaves to be formed on >=1000 samples (default is 200)\n",
    "\n",
    "# data should be numpy array of original (non-encoded) values, should include the target as last feature\n",
    "spn_data = np.concatenate([X_train.values, y_train.values], axis=1)\n",
    "spn = SPN(spn_data, dhandler, normalize_data=False, learn_mspn_kwargs={\"min_instances_slice\":1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6bc46-81e7-4ce7-b153-699cae5e086d",
   "metadata": {},
   "source": [
    "## Using LiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4934e621-421d-4999-a232-d3b4ac9f1917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample is classified as not having a 90 day past due delinquency.\n"
     ]
    }
   ],
   "source": [
    "top_n = 1 # top-n counterfactuals to look for (obtaining more than 1 is implemented only for Gurobi solver)\n",
    "time_limit = 120 # number of seconds to look for a counterfactual, after which the best solution so far is returned\n",
    "# solver to choose\n",
    "solver_name = \"gurobi\" # Gurobi solver is a proprietary solver used in the original experiments. Academic licenses are available.\n",
    "# Use e.g. HiGHS if you do not have access to gurobi solver. Install with: $ pip install highspy\n",
    "# solver_name = \"appsi_highs\"\n",
    "\n",
    "lice = LiCE(\n",
    "    spn,\n",
    "    nn_path=\"tmp_nn.onnx\",\n",
    "    data_handler=dhandler,\n",
    ")\n",
    "\n",
    "# take a sample\n",
    "np.random.seed(1)\n",
    "i = np.random.randint(X_test.shape[0])\n",
    "\n",
    "sample = X_test.iloc[i]\n",
    "enc_sample = dhandler.encode(X_test.iloc[[i]])\n",
    "# we assume binary classification without sigmoid activation in the last layer\n",
    "prediction = nn.predict(enc_sample) > 0\n",
    "if prediction[0][0]:\n",
    "    print(\"The sample is classified as having a 90 day past due delinquency.\")\n",
    "else:\n",
    "    print(\"The sample is classified as not having a 90 day past due delinquency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815ec14-e089-42b4-99d9-ce909bfb9c4d",
   "metadata": {},
   "source": [
    "### Thresholding variant\n",
    "First, we showcase the version where we find the closest counterfactual explanation, such that its **likelihood is above a given threshold**. In this case, we choose the threshold as 25th percentile of the training data.\n",
    "\n",
    "If you get a `GurobiError` stating that model is too big, this means that you should either obtain a license for gurobi or use a different solver (e.g. HiGHS). To set this up, check out the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f93e691-caa6-4c1d-8b20-b2763e4b7eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A globally optimal solution found!\n"
     ]
    }
   ],
   "source": [
    "lls = spn.compute_ll(spn_data)\n",
    "quartile_ll = np.quantile(lls, 0.25) # threhsold on CE likelihood\n",
    "\n",
    "thresholded = lice.generate_counterfactual(\n",
    "    sample,\n",
    "    not prediction,\n",
    "    ll_threshold=quartile_ll,\n",
    "    n_counterfactuals=top_n,\n",
    "    time_limit=time_limit,\n",
    "    solver_name=solver_name\n",
    ")\n",
    "\n",
    "if lice.stats[\"optimal\"]:\n",
    "    print(\"A globally optimal solution found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1337139-b223-47cf-8e3e-ae9fec963429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested counterfactual changes:\n",
      "  Increase the RevolvingUtilizationOfUnsecuredLines parameter by 0.22284848599999996\n",
      "  Increase the NumberOfTime30-59DaysPastDueNotWorse parameter by 1.0\n",
      "  Decrease the DebtRatio parameter by 0.092052859\n",
      "  Decrease the MonthlyIncome parameter by 89.56047399999989\n",
      "  Increase the NumberOfTimes90DaysLate parameter by 3.0\n",
      "  Decrease the NumberOfTime60-89DaysPastDueNotWorse parameter by 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Suggested counterfactual changes:\")\n",
    "for n, val in zip(sample.index, thresholded[0] - sample.values):\n",
    "    if val > 0:\n",
    "        print(f\"  Increase the {n} parameter by {val}\")\n",
    "    elif val < 0:\n",
    "        print(f\"  Decrease the {n} parameter by {-val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e320f2-84c6-406a-abb0-99e0f9b3ec36",
   "metadata": {},
   "source": [
    "### Optimizing variant\n",
    "An aternative to the thresholding variant, here we minimize a linear combination of distance to factual and the likelihood. Set the `alpha` parameter higher if you want to stress the likelihood more, or lower if you want to focus more on proximity.\n",
    "\n",
    "Taking `alpha` approximately equal to (mean CE distance)/(mean CE log-likelihood) works quite well in balancing the two goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26134785-a72f-48fe-86b1-1dab3a56449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A globally optimal solution found!\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1 # coefficient of the linear combination in the objective\n",
    "\n",
    "optimized = lice.generate_counterfactual(\n",
    "    sample,\n",
    "    not prediction,\n",
    "    ll_opt_coefficient=alpha,\n",
    "    n_counterfactuals=top_n,\n",
    "    time_limit=time_limit,\n",
    "    solver_name=solver_name\n",
    ")\n",
    "\n",
    "if lice.stats[\"optimal\"]:\n",
    "    print(\"A globally optimal solution found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff60267-fb30-474b-9c9b-d2d18b3f4f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested counterfactual changes:\n",
      "  Decrease the RevolvingUtilizationOfUnsecuredLines parameter by 0.00619451400000004\n",
      "  Decrease the DebtRatio parameter by 0.092052859\n",
      "  Decrease the MonthlyIncome parameter by 89.56047399999989\n",
      "  Increase the NumberOfTimes90DaysLate parameter by 3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Suggested counterfactual changes:\")\n",
    "for n, val in zip(sample.index, optimized[0] - sample.values):\n",
    "    if val > 0:\n",
    "        print(f\"  Increase the {n} parameter by {val}\")\n",
    "    elif val < 0:\n",
    "        print(f\"  Decrease the {n} parameter by {-val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fbe8614-81ea-45bc-8f81-babc6f0c82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up - remove the neural network model\n",
    "os.remove(\"tmp_nn.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b5af0-6a58-4a50-b9f8-035bc24da275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
