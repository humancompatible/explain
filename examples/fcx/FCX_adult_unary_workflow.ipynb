{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7e4890",
   "metadata": {},
   "source": [
    "# Finding Feasible Counterfactual Explanations (FCX)\n",
    "\n",
    "Feasible Counterfactual Explanations (FCX) is a novel framework that generates realistic and low-cost counterfactuals by enforcing both hard feasibility constraints provided by domain experts and soft causal constraints inferred from data. Built on a modified Variational Autoencoder and optimized with a multi-factor loss function, FCX produces sparse, diverse, and actionable counterfactuals while preserving causal relationships, offering both individual-level explanations and global model feasibility assessments across multiple datasets.\n",
    "\n",
    "### Adult Dataset Example\n",
    "\n",
    "This notebook demonstrates preparation, training, and evaluation of the FCX models  \n",
    "specifically for the **Adult** dataset.  \n",
    "We will:\n",
    "1. Unpack the preprocessed data  \n",
    "2. (Optional) Fine‑tune the black‑box model  \n",
    "3. Train the unary and binary counterfactual generators  \n",
    "4. Evaluate the trained generators  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fd14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the Adult dataset archive\n",
    "#!7z x data.7z -o ../../data -aos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19359765",
   "metadata": {},
   "source": [
    "Load paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c7cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import importlib.util\n",
    "exp_dir = os.path.abspath(os.path.join('..','..','humancompatible','explain'))\n",
    "sys.path.insert(0, exp_dir)\n",
    "\n",
    "fcx_dir = os.path.abspath(os.path.join('..','..','humancompatible','explain','fcx'))\n",
    "sys.path.insert(0, fcx_dir)\n",
    "\n",
    "# compute absolute path to the `scripts` folder\n",
    "scripts_dir = os.path.abspath(\n",
    "    os.path.join('..', '..', 'humancompatible', 'explain', 'fcx', 'scripts')\n",
    ")\n",
    "sys.path.append(scripts_dir)\n",
    "# 1) Compute the full path to your script\n",
    "script_path = os.path.abspath(\n",
    "    os.path.join('..','..','humancompatible','explain','fcx','scripts','blackbox-model-train.py')\n",
    ")\n",
    "# 2) Create a module spec and module object\n",
    "spec = importlib.util.spec_from_file_location(\"blackbox_model_train\", script_path)\n",
    "bb_mod = importlib.util.module_from_spec(spec)\n",
    "\n",
    "# 3) Execute the module in its own namespace\n",
    "spec.loader.exec_module(bb_mod)\n",
    "\n",
    "# 4) Extract the function\n",
    "train_blackbox = bb_mod.train_blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29542f9",
   "metadata": {},
   "source": [
    "## 1. (Optional) Fine‑tune the black‑box model for Adult\n",
    "\n",
    "Run this first if the provided checkpoint isn’t compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fine-tune/load the black‑box model\n",
    "train_blackbox('adult')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f4c28",
   "metadata": {},
   "source": [
    "## 2. Train FCX on the Adult dataset\n",
    "\n",
    "Next, we train the **unary** generator, then the **binary** generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d67c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age      workclass  education marital_status    occupation   race  gender  \\\n",
      "0   39     Government  Bachelors         Single  White-Collar  White    Male   \n",
      "1   50  Self-Employed  Bachelors        Married  White-Collar  White    Male   \n",
      "2   38        Private    HS-grad       Divorced   Blue-Collar  White    Male   \n",
      "3   53        Private     School        Married   Blue-Collar  Other    Male   \n",
      "4   28        Private  Bachelors        Married  Professional  Other  Female   \n",
      "\n",
      "   hours_per_week  income  \n",
      "0              40       0  \n",
      "1              13       0  \n",
      "2              40       0  \n",
      "3              40       0  \n",
      "4              40       0  \n",
      "   age      workclass  education marital_status    occupation   race  gender  \\\n",
      "0   39     Government  Bachelors         Single  White-Collar  White    Male   \n",
      "1   50  Self-Employed  Bachelors        Married  White-Collar  White    Male   \n",
      "2   38        Private    HS-grad       Divorced   Blue-Collar  White    Male   \n",
      "3   53        Private     School        Married   Blue-Collar  Other    Male   \n",
      "4   28        Private  Bachelors        Married  Professional  Other  Female   \n",
      "\n",
      "   hours_per_week  income  \n",
      "0              40       0  \n",
      "1              13       0  \n",
      "2              40       0  \n",
      "3              40       0  \n",
      "4              40       0  \n",
      "The graph has at least one cycle.\n",
      "Cycles found: [(0, 3, 'forward'), (3, 0, 'forward')]\n",
      "Removed edge: (3, 0)\n",
      "Cycle detected. Attempting to remove cycles.\n",
      "Removed edge: (1, 0)\n",
      "Removed edge: (7, 6)\n",
      "Removed edge: (9, 6)\n",
      "Removed edge: (9, 7)\n",
      "Removed edge: (10, 6)\n",
      "Removed edge: (10, 7)\n",
      "Removed edge: (10, 9)\n",
      "Removed edge: (15, 14)\n",
      "Removed edge: (16, 14)\n",
      "Removed edge: (16, 15)\n",
      "Removed edge: (17, 14)\n",
      "Removed edge: (17, 15)\n",
      "Removed edge: (17, 16)\n",
      "Removed edge: (18, 14)\n",
      "Removed edge: (18, 15)\n",
      "Removed edge: (18, 16)\n",
      "Removed edge: (18, 17)\n",
      "No more cycles detected.\n",
      "recon:  tensor(42.0155, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([45.3083], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1358], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.6419, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1030, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([41.8570], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1321], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(38.9038, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1077, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([41.0910], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1283], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(37.9264, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1165, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([40.4532], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1254], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(37.4878, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1354, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([39.3349], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1259], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Avg Loss:  575.4685745239258 9222\n",
      "Time per epoch:  22.16400408744812\n",
      "----Epoch:  0  Loss:  575.4685745239258  Best:  575.4685745239258\n",
      "recon:  tensor(36.2658, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1504, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([38.1743], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1193], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(34.9835, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1702, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([36.9607], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1129], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(34.3578, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1968, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([35.2381], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1130], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(33.8380, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2159, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([33.4598], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1098], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(32.7494, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2283, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([31.2801], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1063], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Avg Loss:  513.8781814575195 9222\n",
      "Time per epoch:  21.83063268661499\n",
      "----Epoch:  1  Loss:  513.8781814575195  Best:  513.8781814575195\n",
      "recon:  tensor(32.2364, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2570, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([29.2135], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1030], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(31.8146, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2820, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([27.0978], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1025], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(31.4322, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2985, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([25.0458], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1020], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(31.0514, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3227, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([22.4851], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1007], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.4039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(30.9117, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3475, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([20.8904], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1008], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Avg Loss:  457.87142181396484 9222\n",
      "Time per epoch:  21.98634433746338\n",
      "----Epoch:  2  Loss:  457.87142181396484  Best:  457.87142181396484\n",
      "recon:  tensor(30.4907, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3845, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([19.1804], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0990], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.4627, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4229, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([18.1660], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0944], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.5488, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4526, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([16.7356], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0939], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.1838, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([15.6429], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0933], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.1633, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5397, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([14.3635], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0946], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Avg Loss:  402.8091125488281 9222\n",
      "Time per epoch:  21.887014150619507\n",
      "----Epoch:  3  Loss:  402.8091125488281  Best:  402.8091125488281\n",
      "recon:  tensor(29.1024, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5719, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([13.8475], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0945], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.9432, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([13.2522], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0933], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.7176, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([12.6507], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0914], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.5230, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.6579, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([12.0424], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0918], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.5437, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([10.9056], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0910], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(2.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Avg Loss:  365.42478942871094 9222\n",
      "Time per epoch:  21.83273983001709\n",
      "----Epoch:  4  Loss:  365.42478942871094  Best:  365.42478942871094\n",
      "Mean time per epoch:  21.94014701843262\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from FCX_unary_generation_adult import train_unary_fcx_vae\n",
    "# Call it for the Adult dataset\n",
    "train_unary_fcx_vae(\n",
    "    'adult',\n",
    "    base_data_dir='../../data/',\n",
    "    base_model_dir='../models/',\n",
    "    batch_size=2048, #2048\n",
    "    epochs=50,\n",
    "    validity=29.0,\n",
    "    feasibility=192.0,\n",
    "    margin=0.764\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f136a16",
   "metadata": {},
   "source": [
    "## 3. Evaluate the trained models (Adult)\n",
    "\n",
    "Run evaluation scripts to compute validity and feasibility metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age      workclass  education marital_status    occupation   race  gender  \\\n",
      "0   39     Government  Bachelors         Single  White-Collar  White    Male   \n",
      "1   50  Self-Employed  Bachelors        Married  White-Collar  White    Male   \n",
      "2   38        Private    HS-grad       Divorced   Blue-Collar  White    Male   \n",
      "3   53        Private     School        Married   Blue-Collar  Other    Male   \n",
      "4   28        Private  Bachelors        Married  Professional  Other  Female   \n",
      "\n",
      "   hours_per_week  income  \n",
      "0              40       0  \n",
      "1              13       0  \n",
      "2              40       0  \n",
      "3              40       0  \n",
      "4              40       0  \n",
      "   age      workclass  education marital_status    occupation   race  gender  \\\n",
      "0   39     Government  Bachelors         Single  White-Collar  White    Male   \n",
      "1   50  Self-Employed  Bachelors        Married  White-Collar  White    Male   \n",
      "2   38        Private    HS-grad       Divorced   Blue-Collar  White    Male   \n",
      "3   53        Private     School        Married   Blue-Collar  Other    Male   \n",
      "4   28        Private  Bachelors        Married  Professional  Other  Female   \n",
      "\n",
      "   hours_per_week  income  \n",
      "0              40       0  \n",
      "1              13       0  \n",
      "2              40       0  \n",
      "3              40       0  \n",
      "4              40       0  \n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  78.11320754716981\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  79.52830188679245\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  79.43396226415095\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  79.33962264150944\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  80.0\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  79.62264150943396\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  79.33962264150944\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  78.49056603773585\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  78.30188679245283\n",
      "sample range:  [1]\n",
      "------------------------------------\n",
      "sample iter  0\n",
      "Mean Validity Score:  78.9622641509434\n",
      "Mean Age-Ed Constraint Score:  58.54241338112306 41.45758661887694 0.5854241338112306\n",
      "Count:  15 820 2 837\n",
      "Pos Count:  6 484 0\n",
      "Pos Percentage:  0.4 0.5902439024390244 0.0\n",
      "Mean Age-Ed Constraint Score:  58.711217183770884 41.288782816229116 0.5871121718377088\n",
      "Count:  14 821 3 838\n",
      "Pos Count:  7 485 0\n",
      "Pos Percentage:  0.5 0.5907429963459196 0.0\n",
      "Mean Age-Ed Constraint Score:  58.433734939759034 41.566265060240966 0.5843373493975903\n",
      "Count:  14 814 2 830\n",
      "Pos Count:  6 479 0\n",
      "Pos Percentage:  0.42857142857142855 0.5884520884520884 0.0\n",
      "Mean Age-Ed Constraint Score:  58.333333333333336 41.666666666666664 0.5833333333333334\n",
      "Count:  20 804 4 828\n",
      "Pos Count:  11 472 0\n",
      "Pos Percentage:  0.55 0.5870646766169154 0.0\n",
      "Mean Age-Ed Constraint Score:  57.95180722891566 42.04819277108434 0.5795180722891566\n",
      "Count:  15 812 3 830\n",
      "Pos Count:  6 475 0\n",
      "Pos Percentage:  0.4 0.5849753694581281 0.0\n",
      "Mean Age-Ed Constraint Score:  58.45410628019324 41.54589371980676 0.5845410628019324\n",
      "Count:  20 806 2 828\n",
      "Pos Count:  10 474 0\n",
      "Pos Percentage:  0.5 0.5880893300248139 0.0\n",
      "Mean Age-Ed Constraint Score:  59.688995215311 40.311004784689 0.59688995215311\n",
      "Count:  15 819 2 836\n",
      "Pos Count:  7 492 0\n",
      "Pos Percentage:  0.4666666666666667 0.6007326007326007 0.0\n",
      "Mean Age-Ed Constraint Score:  57.431629013079665 42.568370986920335 0.5743162901307967\n",
      "Count:  18 821 2 841\n",
      "Pos Count:  7 476 0\n",
      "Pos Percentage:  0.3888888888888889 0.5797807551766139 0.0\n",
      "Mean Age-Ed Constraint Score:  58.095238095238095 41.904761904761905 0.580952380952381\n",
      "Count:  19 819 2 840\n",
      "Pos Count:  8 480 0\n",
      "Pos Percentage:  0.42105263157894735 0.5860805860805861 0.0\n",
      "Mean Age-Ed Constraint Score:  57.66944114149822 42.33055885850178 0.5766944114149822\n",
      "Count:  20 818 3 841\n",
      "Pos Count:  12 473 0\n",
      "Pos Percentage:  0.6 0.578239608801956 0.0\n",
      "Mean Proximity Score:  -2.8179502168091592\n",
      "Mean Proximity Score:  -2.8189307561910377\n",
      "Mean Proximity Score:  -2.806251166961478\n",
      "Mean Proximity Score:  -2.8161138033117137\n",
      "Mean Proximity Score:  -2.816609378070951\n",
      "Mean Proximity Score:  -2.830583695705582\n",
      "Mean Proximity Score:  -2.81763076110456\n",
      "Mean Proximity Score:  -2.82381645538522\n",
      "Mean Proximity Score:  -2.8120912870970907\n",
      "Mean Proximity Score:  -2.8198037969241354\n",
      "Mean Proximity Score:  -2.8235849056603772\n",
      "Mean Proximity Score:  -2.818867924528302\n",
      "Mean Proximity Score:  -2.8150943396226413\n",
      "Mean Proximity Score:  -2.8141509433962266\n",
      "Mean Proximity Score:  -2.8235849056603772\n",
      "Mean Proximity Score:  -2.8207547169811322\n",
      "Mean Proximity Score:  -2.818867924528302\n",
      "Mean Proximity Score:  -2.8160377358490565\n",
      "Mean Proximity Score:  -2.8179245283018868\n",
      "Mean Proximity Score:  -2.8169811320754716\n",
      "----->> Average lof score 1.3648213148117065\n",
      "Final average lof score 1.3648213\n",
      "----->> Average lof score 1.3787927627563477\n",
      "Final average lof score 1.3787928\n",
      "----->> Average lof score 1.3765805959701538\n",
      "Final average lof score 1.3765806\n",
      "----->> Average lof score 1.3849257230758667\n",
      "Final average lof score 1.3849257\n",
      "----->> Average lof score 1.3498486280441284\n",
      "Final average lof score 1.3498486\n",
      "----->> Average lof score 1.4259247779846191\n",
      "Final average lof score 1.4259248\n",
      "----->> Average lof score 1.369778037071228\n",
      "Final average lof score 1.369778\n",
      "----->> Average lof score 1.3864332437515259\n",
      "Final average lof score 1.3864332\n",
      "----->> Average lof score 1.298496127128601\n",
      "Final average lof score 1.2984961\n",
      "----->> Average lof score 1.3695329427719116\n",
      "Final average lof score 1.369533\n",
      "{'adult': {'validity': {'FCX': [[78.11320754716981], [79.52830188679245], [79.43396226415095], [79.33962264150944], [80.0], [79.62264150943396], [79.33962264150944], [78.49056603773585], [78.30188679245283], [78.9622641509434]]}, 'const-score': {'FCX': [array([58.54241338]), array([58.71121718]), array([58.43373494]), array([58.33333333]), array([57.95180723]), array([58.45410628]), array([59.68899522]), array([57.43162901]), array([58.0952381]), array([57.66944114])]}, 'cont-prox': {'FCX': [[-2.8179502168091592], [-2.8189307561910377], [-2.806251166961478], [-2.8161138033117137], [-2.816609378070951], [-2.830583695705582], [-2.81763076110456], [-2.82381645538522], [-2.8120912870970907], [-2.8198037969241354]]}, 'cat-prox': {'FCX': [[-2.8235849056603772], [-2.818867924528302], [-2.8150943396226413], [-2.8141509433962266], [-2.8235849056603772], [-2.8207547169811322], [-2.818867924528302], [-2.8160377358490565], [-2.8179245283018868], [-2.8169811320754716]]}, 'LOF': {'FCX': [1.369533]}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from evaluate_unary_adult import evaluate_adult\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "res = evaluate_adult(\n",
    "    base_data_dir='../../data/',\n",
    "    base_model_dir='../models/',\n",
    "    dataset_name='adult',\n",
    "    pth_name = 'adult-margin-0.764-feasibility-192.0-validity-29.0-epoch-50-fcx-unary.pth'\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3260a1c",
   "metadata": {},
   "source": [
    "Read the results from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c66afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
