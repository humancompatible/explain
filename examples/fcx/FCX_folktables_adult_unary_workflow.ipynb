{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7e4890",
   "metadata": {},
   "source": [
    "# Finding Feasible Counterfactual Explanations (FCX)\n",
    "\n",
    "Feasible Counterfactual Explanations (FCX) is a novel framework that generates realistic and low-cost counterfactuals by enforcing both hard feasibility constraints provided by domain experts and soft causal constraints inferred from data. Built on a modified Variational Autoencoder and optimized with a multi-factor loss function, FCX produces sparse, diverse, and actionable counterfactuals while preserving causal relationships, offering both individual-level explanations and global model feasibility assessments across multiple datasets.\n",
    "\n",
    "### Folktables Dataset Example\n",
    "\n",
    "This notebook demonstrates preparation, training, and evaluation of the FCX models  \n",
    "specifically for the **Folktables** dataset.  \n",
    "We will:\n",
    "1. Unpack the preprocessed data  \n",
    "2. (Optional) Fine‑tune the black‑box model  \n",
    "3. Train the unary and binary counterfactual generators  \n",
    "4. Evaluate the trained generators  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fd14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the Adult dataset archive\n",
    "#!7z x data.7z -o ./data\n",
    "#!pip install torchvision==0.14.1\n",
    "#!conda remove --force pytorch torchvision torchaudio\n",
    "#!pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "#!pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19359765",
   "metadata": {},
   "source": [
    "Load paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c7cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import importlib.util\n",
    "exp_dir = os.path.abspath(os.path.join('..','..','humancompatible','explain'))\n",
    "sys.path.insert(0, exp_dir)\n",
    "\n",
    "fcx_dir = os.path.abspath(os.path.join('..','..','humancompatible','explain','fcx'))\n",
    "sys.path.insert(0, fcx_dir)\n",
    "\n",
    "# compute absolute path to the `scripts` folder\n",
    "scripts_dir = os.path.abspath(\n",
    "    os.path.join('..', '..', 'humancompatible', 'explain', 'fcx', 'scripts')\n",
    ")\n",
    "sys.path.append(scripts_dir)\n",
    "# 1) Compute the full path to your script\n",
    "script_path = os.path.abspath(\n",
    "    os.path.join('..','..','humancompatible','explain','fcx','scripts','blackbox-model-train.py')\n",
    ")\n",
    "# 2) Create a module spec and module object\n",
    "spec = importlib.util.spec_from_file_location(\"blackbox_model_train\", script_path)\n",
    "bb_mod = importlib.util.module_from_spec(spec)\n",
    "\n",
    "# 3) Execute the module in its own namespace\n",
    "spec.loader.exec_module(bb_mod)\n",
    "\n",
    "# 4) Extract the function\n",
    "train_blackbox = bb_mod.train_blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29542f9",
   "metadata": {},
   "source": [
    "## 1. (Optional) Fine‑tune the black‑box model for Folktables\n",
    "\n",
    "Run this first if the provided checkpoint isn’t compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca8bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age                                          workclass  \\\n",
      "0  18.0  Employee of a private for-profit company or bu...   \n",
      "1  53.0                        Federal government employee   \n",
      "2  41.0  Employee of a private for-profit company or bu...   \n",
      "3  18.0  Self-employed in own not incorporated business...   \n",
      "4  21.0                        Federal government employee   \n",
      "\n",
      "                                         education  \\\n",
      "0                Some college but less than 1 year   \n",
      "1                    GED or alternative credential   \n",
      "2                      Regular high school diploma   \n",
      "3                Some college but less than 1 year   \n",
      "4  1 or more years of college credit but no degree   \n",
      "\n",
      "                        marital_status  \\\n",
      "0  Never married or under 15 years old   \n",
      "1  Never married or under 15 years old   \n",
      "2  Never married or under 15 years old   \n",
      "3  Never married or under 15 years old   \n",
      "4  Never married or under 15 years old   \n",
      "\n",
      "                                          occupation  hours_per_week  gender  \\\n",
      "0                       Sales and Office Occupations            21.0  Female   \n",
      "1                                Service Occupations            40.0    Male   \n",
      "2  Natural Resources, Construction, and Maintenan...            40.0    Male   \n",
      "3  Management, Business, Science, and Arts Occupa...             2.0  Female   \n",
      "4                                Service Occupations            50.0    Male   \n",
      "\n",
      "  race  income  \n",
      "0  2.0       0  \n",
      "1  1.0       0  \n",
      "2  1.0       0  \n",
      "3  1.0       0  \n",
      "4  1.0       0  \n",
      "    age                                          workclass  \\\n",
      "0  18.0  Employee of a private for-profit company or bu...   \n",
      "1  53.0                        Federal government employee   \n",
      "2  41.0  Employee of a private for-profit company or bu...   \n",
      "3  18.0  Self-employed in own not incorporated business...   \n",
      "4  21.0                        Federal government employee   \n",
      "\n",
      "                                         education  \\\n",
      "0                Some college but less than 1 year   \n",
      "1                    GED or alternative credential   \n",
      "2                      Regular high school diploma   \n",
      "3                Some college but less than 1 year   \n",
      "4  1 or more years of college credit but no degree   \n",
      "\n",
      "                        marital_status  \\\n",
      "0  Never married or under 15 years old   \n",
      "1  Never married or under 15 years old   \n",
      "2  Never married or under 15 years old   \n",
      "3  Never married or under 15 years old   \n",
      "4  Never married or under 15 years old   \n",
      "\n",
      "                                          occupation  hours_per_week  gender  \\\n",
      "0                       Sales and Office Occupations            21.0  Female   \n",
      "1                                Service Occupations            40.0    Male   \n",
      "2  Natural Resources, Construction, and Maintenan...            40.0    Male   \n",
      "3  Management, Business, Science, and Arts Occupa...             2.0  Female   \n",
      "4                                Service Occupations            50.0    Male   \n",
      "\n",
      "  race  income  \n",
      "0  2.0       0  \n",
      "1  1.0       0  \n",
      "2  1.0       0  \n",
      "3  1.0       0  \n",
      "4  1.0       0  \n",
      "Train set shape: (659112, 45)\n",
      "Validation set shape: (82388, 45)\n",
      "Epoch 1/100 – Train Acc: 552659/659112\n",
      "Epoch 2/100 – Train Acc: 593778/659112\n",
      "Epoch 3/100 – Train Acc: 594648/659112\n",
      "Epoch 4/100 – Train Acc: 594168/659112\n",
      "Epoch 5/100 – Train Acc: 593966/659112\n",
      "Epoch 6/100 – Train Acc: 593790/659112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_blackbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfolktables_adult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kleop\\Downloads\\explain-main\\humancompatible\\explain\\fcx\\scripts\\blackbox-model-train.py:151\u001b[0m, in \u001b[0;36mtrain_blackbox\u001b[1;34m(dataset_name, base_data_dir, base_model_dir, seed, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m    149\u001b[0m     train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    150\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[1;32m--> 151\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m – Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kleop\\Anaconda3\\envs\\explain\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kleop\\Anaconda3\\envs\\explain\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_blackbox('folktables_adult')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f4c28",
   "metadata": {},
   "source": [
    "## 2. Train FCX on the Folktables dataset\n",
    "\n",
    "Next, we train the **unary** generator, then the **binary** generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d67c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age                                          workclass  \\\n",
      "0  18.0  Employee of a private for-profit company or bu...   \n",
      "1  53.0                        Federal government employee   \n",
      "2  41.0  Employee of a private for-profit company or bu...   \n",
      "3  18.0  Self-employed in own not incorporated business...   \n",
      "4  21.0                        Federal government employee   \n",
      "\n",
      "                                         education  \\\n",
      "0                Some college but less than 1 year   \n",
      "1                    GED or alternative credential   \n",
      "2                      Regular high school diploma   \n",
      "3                Some college but less than 1 year   \n",
      "4  1 or more years of college credit but no degree   \n",
      "\n",
      "                        marital_status  \\\n",
      "0  Never married or under 15 years old   \n",
      "1  Never married or under 15 years old   \n",
      "2  Never married or under 15 years old   \n",
      "3  Never married or under 15 years old   \n",
      "4  Never married or under 15 years old   \n",
      "\n",
      "                                          occupation  hours_per_week  gender  \\\n",
      "0                       Sales and Office Occupations            21.0  Female   \n",
      "1                                Service Occupations            40.0    Male   \n",
      "2  Natural Resources, Construction, and Maintenan...            40.0    Male   \n",
      "3  Management, Business, Science, and Arts Occupa...             2.0  Female   \n",
      "4                                Service Occupations            50.0    Male   \n",
      "\n",
      "  race  income  \n",
      "0  2.0       0  \n",
      "1  1.0       0  \n",
      "2  1.0       0  \n",
      "3  1.0       0  \n",
      "4  1.0       0  \n",
      "    age                                          workclass  \\\n",
      "0  18.0  Employee of a private for-profit company or bu...   \n",
      "1  53.0                        Federal government employee   \n",
      "2  41.0  Employee of a private for-profit company or bu...   \n",
      "3  18.0  Self-employed in own not incorporated business...   \n",
      "4  21.0                        Federal government employee   \n",
      "\n",
      "                                         education  \\\n",
      "0                Some college but less than 1 year   \n",
      "1                    GED or alternative credential   \n",
      "2                      Regular high school diploma   \n",
      "3                Some college but less than 1 year   \n",
      "4  1 or more years of college credit but no degree   \n",
      "\n",
      "                        marital_status  \\\n",
      "0  Never married or under 15 years old   \n",
      "1  Never married or under 15 years old   \n",
      "2  Never married or under 15 years old   \n",
      "3  Never married or under 15 years old   \n",
      "4  Never married or under 15 years old   \n",
      "\n",
      "                                          occupation  hours_per_week  gender  \\\n",
      "0                       Sales and Office Occupations            21.0  Female   \n",
      "1                                Service Occupations            40.0    Male   \n",
      "2  Natural Resources, Construction, and Maintenan...            40.0    Male   \n",
      "3  Management, Business, Science, and Arts Occupa...             2.0  Female   \n",
      "4                                Service Occupations            50.0    Male   \n",
      "\n",
      "  race  income  \n",
      "0  2.0       0  \n",
      "1  1.0       0  \n",
      "2  1.0       0  \n",
      "3  1.0       0  \n",
      "4  1.0       0  \n",
      "The graph has at least one cycle.\n",
      "Cycle detected. Attempting to remove cycles.\n",
      "Removed edge: (4, 2)\n",
      "Removed edge: (4, 3)\n",
      "Removed edge: (5, 2)\n",
      "Removed edge: (5, 3)\n",
      "Removed edge: (5, 4)\n",
      "Removed edge: (6, 2)\n",
      "Removed edge: (6, 3)\n",
      "Removed edge: (6, 4)\n",
      "Removed edge: (6, 5)\n",
      "Removed edge: (7, 2)\n",
      "Removed edge: (7, 3)\n",
      "Removed edge: (7, 4)\n",
      "Removed edge: (7, 5)\n",
      "Removed edge: (7, 6)\n",
      "Removed edge: (8, 2)\n",
      "Removed edge: (8, 3)\n",
      "Removed edge: (8, 4)\n",
      "Removed edge: (8, 5)\n",
      "Removed edge: (8, 6)\n",
      "Removed edge: (8, 7)\n",
      "Removed edge: (9, 2)\n",
      "Removed edge: (9, 3)\n",
      "Removed edge: (9, 4)\n",
      "Removed edge: (9, 5)\n",
      "Removed edge: (9, 6)\n",
      "Removed edge: (9, 7)\n",
      "Removed edge: (9, 8)\n",
      "Removed edge: (11, 10)\n",
      "Removed edge: (12, 10)\n",
      "Removed edge: (12, 11)\n",
      "Removed edge: (14, 10)\n",
      "Removed edge: (14, 11)\n",
      "Removed edge: (14, 12)\n",
      "Removed edge: (15, 10)\n",
      "Removed edge: (15, 11)\n",
      "Removed edge: (15, 12)\n",
      "Removed edge: (15, 14)\n",
      "Removed edge: (19, 10)\n",
      "Removed edge: (19, 11)\n",
      "Removed edge: (19, 12)\n",
      "Removed edge: (19, 14)\n",
      "Removed edge: (19, 15)\n",
      "Removed edge: (20, 10)\n",
      "Removed edge: (20, 11)\n",
      "Removed edge: (20, 12)\n",
      "Removed edge: (20, 14)\n",
      "Removed edge: (20, 15)\n",
      "Removed edge: (20, 19)\n",
      "Removed edge: (21, 10)\n",
      "Removed edge: (21, 11)\n",
      "Removed edge: (21, 12)\n",
      "Removed edge: (21, 14)\n",
      "Removed edge: (21, 15)\n",
      "Removed edge: (21, 19)\n",
      "Removed edge: (21, 20)\n",
      "Removed edge: (16, 13)\n",
      "Removed edge: (18, 13)\n",
      "Removed edge: (18, 16)\n",
      "Removed edge: (23, 22)\n",
      "Removed edge: (24, 22)\n",
      "Removed edge: (24, 23)\n",
      "Removed edge: (25, 22)\n",
      "Removed edge: (25, 23)\n",
      "Removed edge: (25, 24)\n",
      "Removed edge: (26, 22)\n",
      "Removed edge: (26, 23)\n",
      "Removed edge: (26, 24)\n",
      "Removed edge: (26, 25)\n",
      "Removed edge: (28, 27)\n",
      "Removed edge: (29, 27)\n",
      "Removed edge: (29, 28)\n",
      "Removed edge: (30, 27)\n",
      "Removed edge: (30, 28)\n",
      "Removed edge: (30, 29)\n",
      "Removed edge: (31, 27)\n",
      "Removed edge: (31, 28)\n",
      "Removed edge: (31, 29)\n",
      "Removed edge: (31, 30)\n",
      "Removed edge: (32, 27)\n",
      "Removed edge: (32, 28)\n",
      "Removed edge: (32, 29)\n",
      "Removed edge: (32, 30)\n",
      "Removed edge: (32, 31)\n",
      "No more cycles detected.\n",
      "recon:  tensor(53.4258, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1036, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([45.0145], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1424], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(50.6065, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([44.3608], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1323], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(48.3599, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.0907, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([43.0351], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1271], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(47.2971, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.0899, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([41.0930], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1268], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(46.2152, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.0892, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([38.4059], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1260], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(45.9460, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.0900, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([36.2492], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1308], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(45.4727, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([34.0281], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1291], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(45.2093, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1069, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([31.1503], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1296], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(44.2071, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1158, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([28.4538], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1268], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(43.7071, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1217, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([25.8529], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1255], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(42.7021, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1314, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([23.1909], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1218], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.5684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(41.4781, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1404, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([20.3919], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1143], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.5202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(41.0168, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1553, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([17.2222], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1125], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.8844, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1637, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([15.2073], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1115], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.4148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.1144, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1746, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([13.3635], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1084], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.7357, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.1890, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([11.0652], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1113], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.2344, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([9.9884], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1078], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.3774, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2216, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([8.4716], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1087], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(39.7559, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2458, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([7.3630], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1050], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.2763, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([5.9666], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1078], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.5910, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.2814, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([4.9664], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1111], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.3274, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3011, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([5.0527], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1093], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.3028, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3135, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([4.7777], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1094], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.1429, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3192, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([4.2165], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1095], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.3722, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3392, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([3.4327], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1109], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(40.0014, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3479, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([3.2451], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1086], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(39.5545, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3617, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([2.4732], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1076], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(39.2255, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3821, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([2.3226], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1065], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(38.5877, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3891, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.7594], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1038], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(37.8496, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3837, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.5733], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.1018], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(37.4432, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3967, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.7169], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0990], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.4125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(36.3146, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4096, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.4643], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0963], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.4351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(35.3411, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4376, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.9292], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0913], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.4466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(35.1457, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4434, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.8982], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0922], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.4659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(34.2489, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4433, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2990], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0898], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.4969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(33.7479, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4725, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2335], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0895], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(33.6220, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4748, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0586], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0894], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(32.6698, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1467], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0868], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.5794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(32.4989, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0551], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0868], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.5788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(31.8701, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5216, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3170], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0848], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(31.2903, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5334, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3436], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0817], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(31.4348, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5554, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3708], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0846], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(30.6513, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5526, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.5833], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0822], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(30.2763, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5806, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.7533], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0814], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.4846, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.7085], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0785], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(30.2348, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.4836], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0827], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.3701, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.6038, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.4940], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0785], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.5135, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2530], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0794], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.0559, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.6006, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2912], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0784], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.5160, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2172], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0817], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(29.1819, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1503], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0796], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.7441, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5715, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3927], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0780], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.5142, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5758, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2014], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0761], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.5195, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2380], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0779], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.5639, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1105], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0784], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.6490, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5408, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0611], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0794], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.7330, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5191, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1536], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0805], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.9412, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5039, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2105], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0764], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(28.0802, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9341], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0776], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.9617, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4913, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1097], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0770], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.3964, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4755, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1070], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0741], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.8664, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4724, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2834], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0779], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.6380, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4688, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1399], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0773], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.8191, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4578, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1078], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0782], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.1187, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4542, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9504], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0742], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.4044, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4528, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9638], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0760], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.9992, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4532, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1713], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0732], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.2223, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4528, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3107], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0746], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.1425, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4494, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3154], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0742], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.0987, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4462, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3466], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0753], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.7813, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4508, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9874], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0724], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.7631, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4547, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9695], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0727], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.1553, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4596, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2340], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0745], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.8727, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4608, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9933], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0742], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.5282, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4597, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9566], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0725], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.3301, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4567, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9438], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0700], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(27.4053, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4667, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0439], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0768], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.7011, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4736, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2292], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0728], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.8565, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4696, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0309], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0740], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.4329, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4722, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9460], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0711], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.4767, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4783, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3214], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0722], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.6468, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4760, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9269], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0735], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.9250, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4811, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9137], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0702], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.3781, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4795, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8406], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0711], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.4316, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4885, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9098], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0714], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.3306, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4867, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9286], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0712], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.9570, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4780, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9218], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0743], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.2083, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4849, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0374], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0708], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.6081, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4815, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2754], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0736], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.0352, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4909, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2588], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0701], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.3372, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4898, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9447], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0723], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.3682, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4776, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6484], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0703], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.1358, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4780, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6036], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0705], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.8840, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4728, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7361], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0680], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.9718, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4786, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1039], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0693], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.1426, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4820, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0032], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0697], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.0477, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4750, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8565], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0694], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.8081, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4630, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7286], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0679], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.6948, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4652, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7142], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0679], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.8008, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4680, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7713], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0673], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.9779, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4701, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8119], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0687], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.0454, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4704, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6063], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0685], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.1490, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4628, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6095], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0682], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.5151, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4594, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6955], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0656], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.9687, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4552, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7554], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0677], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.0733, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4516, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9585], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0680], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.6124, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4504, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8287], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0662], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.7316, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4521, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7913], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0638], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.5576, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4598, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7449], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0651], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.8073, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4455, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6480], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0650], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.0134, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4508, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8879], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0680], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.6437, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4481, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9211], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0638], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.5357, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4460, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6028], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0652], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.6415, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4522, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4695], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0635], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.5289, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4452, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6992], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0625], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.4544, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4441, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6964], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0616], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.8934, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4390, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8149], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0651], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(26.1228, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4360, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9944], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0670], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.7914, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4318, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0619], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0639], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.7769, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4288, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7868], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0620], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8955, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4282, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7064], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0552], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.0444, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5533], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0567], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.1303, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4209, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6179], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0581], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.8081, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4213, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8711], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0602], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.4167, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4202, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9156], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0585], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7003, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7819], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0528], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.4879, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4055, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7587], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0604], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8757, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4111, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5667], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0566], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.6060, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4027, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5733], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0607], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.3446, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4021, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6234], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0570], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.3456, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3916, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7661], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0590], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8634, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3979, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7837], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0558], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8498, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3973, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0516], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0505], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.0333, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3921, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7243], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0552], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.3838, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3823, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6589], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0520], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.3308, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3940, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6305], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0577], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5779, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3824, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4538], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0525], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.3363, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3816, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6496], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0529], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.2965, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3947, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8891], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0560], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.3566, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3869, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8932], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0560], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.1133, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3839, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8194], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0537], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8808, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3768, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8576], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0507], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7773, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3798, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7217], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0493], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.2554, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3838, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7195], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0532], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7549, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3883, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8029], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0495], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.9465, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3823, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6374], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0528], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.0633, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3893, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5589], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0510], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.0273, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3892, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6288], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0515], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.0868, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3841, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7961], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0493], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.9846, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3913, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6693], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0492], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8843, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3905, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6584], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0505], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.0234, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3882, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8176], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0493], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.9325, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3892, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9375], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0454], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.9734, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3928, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6915], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0483], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8121, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3936, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5572], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0483], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6936, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3907, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5895], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0505], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7742, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3854, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8112], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0477], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6869, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3926, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9205], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0446], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5724, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3966, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8634], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0474], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5114, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3947, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8508], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0437], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3028, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8225], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0418], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3984, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6884], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0396], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4711, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4067, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7956], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0441], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2397, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3987, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6458], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0387], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8183, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3992, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5972], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0450], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(25.2521, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4040, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6758], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0458], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7929, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4002, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8229], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0470], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8733, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4071, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0655], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0425], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5070, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3983, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9306], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0381], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2331, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3989, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7499], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0402], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6612, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4001, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7163], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0371], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8966, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3929, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7475], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0441], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5041, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3973, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6599], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0411], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8648, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3902, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6240], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0445], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.9144, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3869, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0342], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0421], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5191, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3877, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1257], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0352], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6411, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3957, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8553], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0378], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5268, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3872, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6702], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0455], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.6949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5165, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3859, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5518], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0428], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7991, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3875, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6351], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0377], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7477, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3877, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7864], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0387], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.9826, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3879, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7155], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0464], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5485, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3975, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8391], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0385], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4984, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4060, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6941], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0425], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6432, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3963, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6295], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0401], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6316, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3940, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6087], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0402], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4761, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3958, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7465], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0335], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3899, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4004, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8055], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0377], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6456, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3903, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1536], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0345], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5872, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3900, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2450], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0383], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5631, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3894, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7120], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0363], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4845, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3875, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5689], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0344], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0984, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5866], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0335], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4526, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3810, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8651], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0300], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3166, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3801, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0865], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0328], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2545, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3890, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0872], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0329], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0658, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3962, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6914], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0333], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5031, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3934, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6273], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0326], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6804, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3941, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7283], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0334], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5678, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3935, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8356], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0300], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.8211, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3955, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8159], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0308], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6182, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4039, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8231], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0290], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0312, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4039, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9148], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0321], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5979, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4013, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6234], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0298], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3430, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3986, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6798], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0281], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5594, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3937, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6483], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0307], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0317, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3890, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5817], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0310], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3756, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3985, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7777], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0327], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5092, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3942, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2896], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0298], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7421, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3912, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.3989], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0359], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7725, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3889, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9522], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0314], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1942, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3936, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6286], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0316], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0960, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3975, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5166], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0233], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1896, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3887, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5476], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0270], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0443, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3828, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7142], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0289], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1305, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3849, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8803], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0317], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7256, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3735, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1157], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0356], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5663, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3779, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1321], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0354], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8630, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3834, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7654], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0291], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1645, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3903, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7193], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0309], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5594, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3938, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7228], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0337], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4214, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3816, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8797], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0266], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3653, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3960, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0012], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0234], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2295, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4010, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8465], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0229], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5636, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4031, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7612], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0292], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3158, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3978, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6126], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0342], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8014, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3939, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5878], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0267], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6803, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3960, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7700], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0350], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Avg Loss:  11876.121406555176 465748\n",
      "----Epoch: 0 Loss: 11876.121406555176 Best: 11876.121406555176\n",
      "recon:  tensor(24.6678, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3985, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8022], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0290], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2735, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3949, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7788], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0222], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2767, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4040, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7826], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0265], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2499, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3873, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7398], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0312], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2193, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3921, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8100], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0275], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8833, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3979, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7294], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0263], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7287, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3877, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7320], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0275], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7868, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3831, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7468], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0297], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2331, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3944, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9013], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0277], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4443, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3824, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8609], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0261], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5232, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3727, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6225], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0286], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7769, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3914, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7892], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0230], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2223, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3882, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8129], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0262], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9553, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3808, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9470], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0221], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3859, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4009, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8800], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0259], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6762, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3952, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7411], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0276], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2265, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3840, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6619], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0310], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0860, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3954, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7934], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0214], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0405, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3927, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0517], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0229], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9337, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4005, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6667], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0316], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3512, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3969, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6156], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0320], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8827, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4035, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7491], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0237], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6501, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3810, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9630], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0254], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8461, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3822, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9482], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0204], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3324, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3912, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6657], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0281], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1319, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3912, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6372], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0237], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0102, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3823, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7674], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0248], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0896, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3899, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8157], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0285], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5732, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3891, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0975], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0288], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.5852, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3897, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1836], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0257], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9005, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3869, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8748], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0208], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2502, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3830, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5725], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0194], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4041, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3844, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6478], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0207], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6941, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3878, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0739], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0189], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.9335, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3884, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8556], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0281], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.4295, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3918, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6802], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0262], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0567, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3847, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6697], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0255], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.7535, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3943, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8730], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0267], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2314, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3935, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8160], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0251], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3276, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3894, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6684], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0228], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3080, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3758, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5119], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0293], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9274, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3793, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5243], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0275], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8919, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3898, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8257], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0270], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1462, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3797, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9442], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0223], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1812, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3760, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1013], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0279], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9050, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3730, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9181], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0229], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8054, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3835, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7562], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0218], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4354, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3765, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6909], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0224], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7551, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3837, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6719], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0280], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7825, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3834, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7064], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0235], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9112, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3868, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8667], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0205], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2064, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3833, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8021], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0250], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1550, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3757, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7283], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0279], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9412, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3797, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5561], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0236], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7790, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3848, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6758], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0214], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5746, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3812, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7499], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0225], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6900, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4048, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7582], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0190], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2067, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4029, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6730], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0238], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8313, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3951, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7546], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0217], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4253, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3979, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9283], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0205], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7705, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3976, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0295], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0240], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0782, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4019, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9020], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0216], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6963, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4021, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7357], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0268], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7331, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4016, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5221], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0200], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9297, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3971, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5561], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0217], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8593, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3977, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7376], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0150], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0013, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4020, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8004], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0231], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0301, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4003, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8299], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0275], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7756, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3920, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5825], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0251], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6523, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4034, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5636], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0259], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5489, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3988, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5946], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0183], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8473, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3895, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7486], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0209], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8024, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4048, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8381], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0256], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5474, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3970, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6925], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0233], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9269, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4076, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7878], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0219], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5436, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4020, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7291], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0162], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3112, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3934, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8527], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0156], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5394, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3883, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7946], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0141], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7018, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3860, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5655], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0159], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8054, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3836, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7180], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0159], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5782, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3901, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7702], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0116], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0469, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3919, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9027], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0171], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8305, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3904, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6651], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0206], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7931, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3899, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5262], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0165], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8983, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3824, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5670], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0117], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2096, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3806, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8988], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0161], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.3128, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3760, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1046], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0141], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9066, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3907, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1230], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0154], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6569, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4081, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6570], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0151], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1374, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4111, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5956], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0153], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2276, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4074, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6398], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0153], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9540, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3931, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7222], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0102], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8461, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3853, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7539], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0169], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0241, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3826, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7190], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0174], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6967, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3807, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6882], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0228], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6944, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3919, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8139], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0173], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8196, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3928, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7061], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0140], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.6521, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3917, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8882], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0134], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8712, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3833, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6678], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0103], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4987, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3969, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5074], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0159], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4592, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3917, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6229], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0149], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7777, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3914, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8323], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0132], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7399, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3944, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9614], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0093], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4072, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3888, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7714], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0172], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7571, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4016, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5776], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0188], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2425, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4030, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5038], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0177], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7168, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3952, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4390], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0117], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4195, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3832, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6890], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0146], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2204, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3753, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0711], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0056], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4549, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3935, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9939], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0153], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.8220, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3901, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7871], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0127], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0715, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4030, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6018], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0120], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3087, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3873, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5952], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0064], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5197, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3851, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7241], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0135], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7427, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3788, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8714], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0175], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3851, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3848, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7744], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0181], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0721, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3947, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5800], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0182], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7328, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3966, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7138], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0126], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.2596, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3900, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8263], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0113], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4194, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3855, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7024], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0092], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4868, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3910, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5717], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0146], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4519, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3933, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5363], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0089], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3018, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3830, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6925], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0118], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9733, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3900, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9819], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0126], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6159, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4042, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8120], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0150], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5982, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3970, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6330], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0136], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4833, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4019, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6751], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0122], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8569, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4017, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8737], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0174], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4835, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4028, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7312], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0097], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5238, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4048, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6370], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0064], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4748, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4038, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5679], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0099], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6471, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4042, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6844], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0093], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6394, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4024, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7105], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0108], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1857, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4057, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7119], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0115], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3836, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4106, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7141], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0133], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7477, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3949, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7952], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0101], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7046, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3962, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8016], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0118], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5007, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.3940, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7298], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0097], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5950, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4119, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5822], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0154], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2425, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4224, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5739], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0154], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6737, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4157, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6966], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0136], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7642, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4015, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7921], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0178], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3541, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4030, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8525], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0123], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9851, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4086, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8440], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0148], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3985, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4089, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6431], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0088], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2252, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4188, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5243], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0109], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3276, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4126, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6104], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0109], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.8010, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4069, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7868], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0144], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1367, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4095, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0591], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0217], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6968, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4047, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8846], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0133], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4805, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4092, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4920], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0168], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4761, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4120, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4872], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0200], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5489, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4113, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5566], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0113], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.0347, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4195, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7122], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0168], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4320, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4212, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8578], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0220], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2629, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4312, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8198], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0228], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.9711, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4312, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7888], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0164], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0429, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7768], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0077], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3017, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4126, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7877], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0091], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3524, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4053, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6218], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0135], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3099, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4224, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4939], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0151], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1426, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4116, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8496], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0156], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4986, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4125, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.2811], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0164], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3326, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4073, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.1094], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0142], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2073, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4101, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5283], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0132], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2176, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4203, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4354], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0129], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.8971, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4148, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6658], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0077], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(24.1302, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4174, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9004], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0106], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.9240, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4307, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8726], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0131], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2750, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4369, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6481], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0045], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2206, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4391, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6721], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0113], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3641, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4375, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7467], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0128], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1900, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4348, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8648], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0071], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2924, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4298, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9178], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0046], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5590, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4303, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7061], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0097], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3943, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4400, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6221], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0153], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6697, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4384, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4853], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0159], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7198, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4267, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6241], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0237], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0522, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4301, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8574], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0161], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0602, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4365, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0107], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0090], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0372, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4269, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7764], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0117], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1148, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4285, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7171], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0124], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2130, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4254, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6011], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0065], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.9407, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4212, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5283], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0092], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4720, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4359, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6501], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0088], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3161, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4447, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8178], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0146], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1572, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7882], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0004], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1790, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4484, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7958], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0130], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0297, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4285, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7135], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0076], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1150, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4345, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7357], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0055], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1473, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4322, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7885], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0132], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3745, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4331, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7691], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0075], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0856, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4405, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6714], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0111], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.6288, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4182, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6334], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0098], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1273, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4423, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8815], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0106], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5276, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4396, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9351], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0098], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3878, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4403, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8866], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0136], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0501, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4415, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7400], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0099], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2924, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4379, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5580], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0138], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0282, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4532, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5731], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0078], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0075, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4416, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6863], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0099], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1469, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4344, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8030], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0120], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.5376, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4489, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9553], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0098], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.6899, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4692, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8711], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0158], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.7430, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4575, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6099], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0054], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2155, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4430, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6460], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0013], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.8224, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4395, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6340], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0070], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1245, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4536, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7806], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0164], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.9598, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4602, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8457], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0118], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0367, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4483, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8563], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0111], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1028, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4419, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7373], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0105], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0238, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4510, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6798], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0022], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0390, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4404, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7297], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0018], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.7587, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4430, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7207], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0087], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.3571, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4451, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0125], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0062], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.9531, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4516, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([1.0121], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0074], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.8119, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4586, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9611], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0125], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.7541, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4549, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6386], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0039], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.7020, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4492, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4075], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0076], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.1000, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4332, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6146], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0000], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.6008, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4382, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7865], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0036], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.2289, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4388, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7599], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0020], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.9578, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4388, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.6945], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0071], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0223, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4295, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.5625], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0109], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0502, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4314, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.8641], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0035], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.8249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.0187, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4420, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.9976], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0009], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(23.4069, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4445, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.7677], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0106], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "recon:  tensor(22.5000, device='cuda:0', grad_fn=<NegBackward0>)  KL:  tensor(0.4535, device='cuda:0', grad_fn=<MeanBackward0>)  Validity:  tensor([0.4523], device='cuda:0', grad_fn=<NegBackward0>) sparsity:  tensor([2.0042], device='cuda:0', grad_fn=<MulBackward0>) reg_loss:  tensor(4.7668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Avg Loss:  10053.700908660889 465748\n",
      "----Epoch: 1 Loss: 10053.700908660889 Best: 10053.700908660889\n",
      "Mean time per epoch: 1147.12291431427\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from FCX_unary_generation_folktables_adult import train_unary_fcx_vae\n",
    "#!pip install networkx==2.8\n",
    "# Call it for the Adult dataset\n",
    "train_unary_fcx_vae(\n",
    "    'folktables_adult',\n",
    "    base_data_dir='../../data/',\n",
    "    base_model_dir='../models/',\n",
    "    batch_size=2048, #2048\n",
    "    epochs=25, #50\n",
    "    validity=29.0,\n",
    "    feasibility=192.0,\n",
    "    margin=0.764\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f136a16",
   "metadata": {},
   "source": [
    "## 3. Evaluate the trained models (Folktables)\n",
    "\n",
    "Run evaluation scripts to compute validity and feasibility metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: 0, 9: 1, 5: 2, 0: 1, 2: 1, 11: 1, 4: 1, 1: 1, 8: 2, 6: 0, 3: 3, 7: 0}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'evaluate_folktables_adult' from 'evaluate_unary_folktables_adult' (c:\\Users\\kleop\\Downloads\\explain-main\\humancompatible\\explain\\fcx\\evaluate_unary_folktables_adult.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevaluate_unary_folktables_adult\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate_folktables_adult\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'evaluate_folktables_adult' from 'evaluate_unary_folktables_adult' (c:\\Users\\kleop\\Downloads\\explain-main\\humancompatible\\explain\\fcx\\evaluate_unary_folktables_adult.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from evaluate_unary_folktables_adult import evaluate_folktables_adult\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "res = evaluate_folktables_adult(\n",
    "    base_data_dir='../../data/',\n",
    "    base_model_dir='../models/',\n",
    "    dataset_name='folktables_adult',\n",
    "    pth_name = 'folktables_adult-margin-0.764-feasibility-192.0-validity-29.0-epoch-25-fcx-unary.pth'\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3260a1c",
   "metadata": {},
   "source": [
    "Read the results from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c66afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
